{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Cooking 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying to utilize some efficiency techniques I saw in the forums\n",
    "from pandas import Series, DataFrame # I don't know how to use Pandas\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk #natural language toolkit\n",
    "import re #regular expressions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import LinearSVC #Let's see what linear SVC does\n",
    "from sklearn.metrics import classification_report #not sure about this\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # need to learn this too\n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cuisine     id                                        ingredients\n",
      "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
      "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
      "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
      "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
      "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "train_data = pd.read_json(\"train.json\")\n",
    "print train_data.head() #great, we can use .head() with pandas! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10259\n",
      "1    25693\n",
      "2    20130\n",
      "3    22213\n",
      "4    13162\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# what else can we do? \n",
    "print train_data['id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not sure what the following line does exactly, need to figure it out\n",
    "train_data['ingredients_clean_string'] = [' , '.join(z).strip() for z in train_data['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cuisine     id                                        ingredients  \\\n",
      "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
      "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
      "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
      "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
      "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
      "\n",
      "                            ingredients_clean_string  \n",
      "0  romaine lettuce , black olives , grape tomatoe...  \n",
      "1  plain flour , ground pepper , salt , tomatoes ...  \n",
      "2  eggs , pepper , salt , mayonaise , cooking oil...  \n",
      "3               water , vegetable oil , wheat , salt  \n",
      "4  black pepper , shallots , cornflour , cayenne ...  \n"
     ]
    }
   ],
   "source": [
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(train_data['ingredients'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n"
     ]
    }
   ],
   "source": [
    "# Looks like 'ingredients' contains a list of individual strings of ingredients\n",
    "print train_data['ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### So then what does 'ingredients_clean_string' contain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'unicode'>\n",
      "romaine lettuce , black olives , grape tomatoes , garlic , pepper , purple onion , seasoning , garbanzo beans , feta cheese crumbles\n"
     ]
    }
   ],
   "source": [
    "print type(train_data['ingredients_clean_string'][0])\n",
    "print train_data['ingredients_clean_string'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looks like one continuous string. So that means that the above\n",
    "# code added in a ' , ' between every ingredient and stuck it together. \n",
    "# What does .strip() do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to my research, .strip() with no arguments will remove leading\n",
    "# and trailing whitespace (spaces), and if you specify characters, it \n",
    "# will remove those from the string if they're leading or trailing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test string. com %\n",
      "this is a test string. com \n",
      "is is a test string. com %\n"
     ]
    }
   ],
   "source": [
    "test_string = 'this is a test string. com %'\n",
    "print test_string\n",
    "test_string_2 = test_string.strip('%')\n",
    "print test_string_2\n",
    "test_string_3 = test_string.strip(' tho')\n",
    "print test_string_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", test ,\n"
     ]
    }
   ],
   "source": [
    "# Great! I understand .strip(). so then .join() joins it all into a string? \n",
    "test_string_next = ' , test , '\n",
    "print test_string_next.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'd', 'u', 't * e * s * t']\n"
     ]
    }
   ],
   "source": [
    "test_list = ['a', 'b', 'd', 'u', 'test']\n",
    "test_list_string = [' * '.join(j) for j in test_list]\n",
    "print test_list_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'd', 'u', 't * e * s * t']\n"
     ]
    }
   ],
   "source": [
    "test_list_string2 = [' * '.join(j).strip() for j in test_list]\n",
    "print test_list_string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a * u * d * i * b * l * e', 'b * e * f * o * r * e *', 'd * o * g *   * t * e * s * t', 'u * n * d * e * r * s * t * a * n * d * i * n * g *   * i * s *   * k * e * y', 't * e * s * t']\n"
     ]
    }
   ],
   "source": [
    "tester_list = ['audible', 'before ', 'dog test', 'understanding is key', 'test']\n",
    "test_list_string3 = [' * '.join(j).strip() for j in tester_list]\n",
    "print test_list_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audible * before  * dog test * understanding is key * test\n"
     ]
    }
   ],
   "source": [
    "# Looks like you put something iterable into .join() as an argument, \n",
    "# and that joins it all together for you. great! \n",
    "test_list_string4 = ' * '.join(tester_list)\n",
    "print test_list_string4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]',\\\n",
    "                                                                                ' ', line)) \n",
    "                                           for line in lists]).strip() for lists in train_data['ingredients']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    romaine lettuce black olives grape tomatoes ga...\n",
      "1    plain flour ground pepper salt tomato ground b...\n",
      "2    egg pepper salt mayonaise cooking oil green ch...\n",
      "3                       water vegetable oil wheat salt\n",
      "4    black pepper shallot cornflour cayenne pepper ...\n",
      "Name: ingredients_string, dtype: object\n",
      "romaine lettuce black olives grape tomatoes garlic pepper purple onion seasoning garbanzo beans feta cheese crumbles\n",
      "<type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "print train_data['ingredients_string'].head()\n",
    "print train_data['ingredients_string'][0]\n",
    "print type(train_data['ingredients_string'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_train = train_data['ingredients_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So let's look into what the above lines did. We get ' '.join, \n",
    "# that part adds together the items in the list with a space. \n",
    "# The interior part takes each set of ingredients, and then for each\n",
    "# takes each individual ingredient string and does something with\n",
    "# regular expressions and then lematizes that. So the questions is, \n",
    "# what does re.sub('[^A-Za-z]',' ', line) do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apparently ^ means that any character that doesn't fall into \n",
    "# the following category is matched. so Sub takes the string listed \n",
    "# as the third argument, tries to match anything listed in the first one\n",
    "# (here as anything that's not a letter), and replaces that with a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes this is a test   woo h  y\n"
     ]
    }
   ],
   "source": [
    "tst_strng = 'yes this is a test & woo h**y'\n",
    "tst_strng2 = re.sub('[^A-Za-z]',' ', tst_strng)\n",
    "print tst_strng2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes this is a test   woo h  y\n"
     ]
    }
   ],
   "source": [
    "tst_strng3 = WordNetLemmatizer().lemmatize(tst_strng2)\n",
    "print tst_strng3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-99-7575a2a6c82b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-99-7575a2a6c82b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    result = re.search('[^A-Za-z]', line) for line in lists for lists in train_data['ingredients']\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "result = re.search('[^A-Za-z]', line) for line in lists for lists in train_data['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_sre.SRE_Match object at 0x166ab1718>, <_sre.SRE_Match object at 0x166ab1648>, <_sre.SRE_Match object at 0x166ab1578>, <_sre.SRE_Match object at 0x166ab14a8>, <_sre.SRE_Match object at 0x166ab13d8>, <_sre.SRE_Match object at 0x166ab1308>, <_sre.SRE_Match object at 0x166ab1238>, <_sre.SRE_Match object at 0x166ab1168>, <_sre.SRE_Match object at 0x166ab1098>, <_sre.SRE_Match object at 0x166ab1780>, <_sre.SRE_Match object at 0x166ab17e8>, <_sre.SRE_Match object at 0x166ab1850>, <_sre.SRE_Match object at 0x166ab18b8>, <_sre.SRE_Match object at 0x166ab1920>, <_sre.SRE_Match object at 0x166ab1988>, <_sre.SRE_Match object at 0x166ab19f0>, <_sre.SRE_Match object at 0x166ab1a58>, <_sre.SRE_Match object at 0x166ab1ac0>, <_sre.SRE_Match object at 0x166ab1b28>]\n"
     ]
    }
   ],
   "source": [
    "# What did I do wrong? No brackets around it\n",
    "result = [(re.search('[^A-Za-z]', line)) for line in lists for lists in train_data['ingredients']]\n",
    "print result[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'sugar', u'large eggs', u'all-purpose flour', u'baking soda', u'buttermilk', u'honey', u'corn oil', u'yellow corn meal', u'unsalted butter', u'salt']\n",
      "sugar large eggs all purpose flour baking soda buttermilk honey corn oil yellow corn meal unsalted butter salt\n"
     ]
    }
   ],
   "source": [
    "print train_data['ingredients'][53]\n",
    "print train_data['ingredients_string'][53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looks like it just takes out non-numeric characters and makes them spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'orange juice concentrate', u'pumpkin pur\\xe9e', u'marshmallow creme', u'toasted pecans', u'maple syrup', u'ground cinnamon', u'gingersnap', u'ground nutmeg', u'cream cheese']\n",
      "orange juice concentrate pumpkin pur e marshmallow creme toasted pecans maple syrup ground cinnamon gingersnap ground nutmeg cream cheese\n"
     ]
    }
   ],
   "source": [
    "print train_data['ingredients'][68]\n",
    "print train_data['ingredients_string'][68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_train = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range = ( 1 , 1 ), analyzer=\"word\", \n",
    "                             max_df = .57, binary=False, token_pattern=r'\\w+', sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_train = vectorizer_train.fit_transform(corpus_train).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_json(\"test.json\") \n",
    "test_data['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]',\\\n",
    "                                                                                  ' ', line)) \n",
    "                                             for line in lists]).strip() for lists in test_data['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_test = test_data['ingredients_string']\n",
    "tf_idf_test = vectorizer_train.transform(corpus_test)\n",
    "\n",
    "predictors_train = tf_idf_train\n",
    "targets_train = train_data['cuisine']\n",
    "predictors_test = tf_idf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'C':[1, 10]}\n",
    "clf = LogisticRegression()\n",
    "classifier = grid_search.GridSearchCV(clf, parameters)\n",
    "classifier = classifier.fit(predictors_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(predictors_test)\n",
    "test_data['cuisine'] = predictions\n",
    "\n",
    "test_data[['id' , 'cuisine' ]].to_csv(\"submission_2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning about pickle\n",
    "import pickle\n",
    "\n",
    "save_classifier = open('saved_classifier_test_2.pickle', \"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.78862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
